{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing Code and importing all libraries (Shared Across All Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as GDA\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Loading the dataset\n",
    "file_path = './DATA/healthcare-dataset-stroke-data.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Data Cleaning\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le \n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data.drop(columns=['id', 'stroke'])  # Features\n",
    "y = data['stroke']  # Target\n",
    "\n",
    "# Split into train (70%), test (20%), and validation (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       944\n",
      "           1       0.12      0.76      0.21        42\n",
      "\n",
      "    accuracy                           0.76       986\n",
      "   macro avg       0.56      0.76      0.54       986\n",
      "weighted avg       0.95      0.76      0.83       986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[720 224]\n",
      " [ 10  32]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training with Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluating on Test Set\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       944\n",
      "           1       0.11      0.29      0.16        42\n",
      "\n",
      "    accuracy                           0.87       986\n",
      "   macro avg       0.54      0.59      0.54       986\n",
      "weighted avg       0.93      0.87      0.90       986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[844 100]\n",
      " [ 30  12]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training with Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluating with Test Set\n",
    "y_pred_test = dt_model.predict(X_test)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       944\n",
      "           1       0.11      0.21      0.15        42\n",
      "\n",
      "    accuracy                           0.89       986\n",
      "   macro avg       0.54      0.57      0.54       986\n",
      "weighted avg       0.93      0.89      0.91       986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[872  72]\n",
      " [ 33   9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training with Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluating on Test Set\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85       944\n",
      "           1       0.12      0.76      0.20        42\n",
      "\n",
      "    accuracy                           0.75       986\n",
      "   macro avg       0.55      0.75      0.53       986\n",
      "weighted avg       0.95      0.75      0.82       986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[705 239]\n",
      " [ 10  32]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training with SVM\n",
    "svm_model = SVC(random_state=42, kernel='linear', probability=True)\n",
    "svm_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluating on Test Set\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "print(\"Support Vector Machine\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting (XGBoost)\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       944\n",
      "           1       0.08      0.17      0.11        42\n",
      "\n",
      "    accuracy                           0.88       986\n",
      "   macro avg       0.52      0.54      0.52       986\n",
      "weighted avg       0.92      0.88      0.90       986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[864  80]\n",
      " [ 35   7]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train Gradient Boosting (XGBoost)\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')  \n",
    "xgb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate on Test Set\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "print(\"Gradient Boosting (XGBoost)\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Gaussian Discriminant Analysis GDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Discriminant Analysis (GDA)\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85       944\n",
      "           1       0.12      0.74      0.20        42\n",
      "\n",
      "    accuracy                           0.75       986\n",
      "   macro avg       0.55      0.75      0.53       986\n",
      "weighted avg       0.95      0.75      0.83       986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[712 232]\n",
      " [ 11  31]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train Gaussian Discriminant Analysis (GDA)\n",
    "gda_model = GDA()  \n",
    "gda_model.fit(X_resampled, y_resampled) \n",
    "\n",
    "# Evaluate on Test Set\n",
    "y_pred_test = gda_model.predict(X_test)  \n",
    "print(\"Gaussian Discriminant Analysis (GDA)\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy: 0.73\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84       944\n",
      "           1       0.11      0.79      0.20        42\n",
      "\n",
      "    accuracy                           0.73       986\n",
      "   macro avg       0.55      0.76      0.52       986\n",
      "weighted avg       0.95      0.73      0.81       986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[688 256]\n",
      " [  9  33]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb_model = GaussianNB()  \n",
    "nb_model.fit(X_resampled, y_resampled)  \n",
    "\n",
    "# Evaluate on Test Set\n",
    "y_pred_test = nb_model.predict(X_test) \n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the algorithms used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (macro)</th>\n",
       "      <th>Recall (macro)</th>\n",
       "      <th>F1-score (macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.762677</td>\n",
       "      <td>0.555651</td>\n",
       "      <td>0.762308</td>\n",
       "      <td>0.537490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868154</td>\n",
       "      <td>0.536409</td>\n",
       "      <td>0.589891</td>\n",
       "      <td>0.542169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.893509</td>\n",
       "      <td>0.537324</td>\n",
       "      <td>0.569007</td>\n",
       "      <td>0.544777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.747465</td>\n",
       "      <td>0.552048</td>\n",
       "      <td>0.754363</td>\n",
       "      <td>0.527191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting (XGBoost)</td>\n",
       "      <td>0.883367</td>\n",
       "      <td>0.520764</td>\n",
       "      <td>0.540960</td>\n",
       "      <td>0.523064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaussian Discriminant Analysis(GDA)</td>\n",
       "      <td>0.753550</td>\n",
       "      <td>0.551328</td>\n",
       "      <td>0.746166</td>\n",
       "      <td>0.528754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.731237</td>\n",
       "      <td>0.550637</td>\n",
       "      <td>0.757264</td>\n",
       "      <td>0.518954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Algorithm  Accuracy  Precision (macro)  \\\n",
       "0                  Logistic Regression  0.762677           0.555651   \n",
       "1                        Decision Tree  0.868154           0.536409   \n",
       "2                        Random Forest  0.893509           0.537324   \n",
       "3               Support Vector Machine  0.747465           0.552048   \n",
       "4          Gradient Boosting (XGBoost)  0.883367           0.520764   \n",
       "5  Gaussian Discriminant Analysis(GDA)  0.753550           0.551328   \n",
       "6                          Naive Bayes  0.731237           0.550637   \n",
       "\n",
       "   Recall (macro)  F1-score (macro)  \n",
       "0        0.762308          0.537490  \n",
       "1        0.589891          0.542169  \n",
       "2        0.569007          0.544777  \n",
       "3        0.754363          0.527191  \n",
       "4        0.540960          0.523064  \n",
       "5        0.746166          0.528754  \n",
       "6        0.757264          0.518954  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"Algorithm\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision (macro)\": [],\n",
    "    \"Recall (macro)\": [],\n",
    "    \"F1-score (macro)\": []\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_model(model, algorithm_name, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    results[\"Algorithm\"].append(algorithm_name)\n",
    "    results[\"Accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    results[\"Precision (macro)\"].append(report[\"macro avg\"][\"precision\"])\n",
    "    results[\"Recall (macro)\"].append(report[\"macro avg\"][\"recall\"])\n",
    "    results[\"F1-score (macro)\"].append(report[\"macro avg\"][\"f1-score\"])\n",
    "\n",
    "# Evaluate pre-trained models\n",
    "evaluate_model(lr_model, \"Logistic Regression\", X_test, y_test)\n",
    "evaluate_model(dt_model, \"Decision Tree\", X_test, y_test)\n",
    "evaluate_model(rf_model, \"Random Forest\", X_test, y_test)\n",
    "evaluate_model(svm_model, \"Support Vector Machine\", X_test, y_test)\n",
    "evaluate_model(xgb_model, \"Gradient Boosting (XGBoost)\", X_test, y_test)\n",
    "evaluate_model(gda_model, \"Gaussian Discriminant Analysis(GDA)\", X_test, y_test)\n",
    "evaluate_model(nb_model, \"Naive Bayes\", X_test, y_test)\n",
    "# Tabulate Results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
